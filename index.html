<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Real-Time ASL Translator (ONNX in Browser)</title>
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
  <style>
    body { font-family: sans-serif; text-align: center; }
    video, canvas { border: 1px solid #ccc; margin: 10px; }
    #prediction { font-size: 2em; margin-top: 10px; }
  </style>
</head>
<body>
  <h1>üß† ASL Sign Language Translator</h1>
  <video id="webcam" autoplay playsinline width="224" height="224"></video>
  <canvas id="canvas" width="224" height="224" style="display: none;"></canvas>
  <div id="prediction">‚è≥ Loading...</div>

  <script>
    const labels = Array.from({ length: 26 }, (_, i) => String.fromCharCode(65 + i));
    let session;

    async function init() {
      session = await ort.InferenceSession.create("ASL.onnx");
      document.getElementById("prediction").textContent = "‚úÖ Model Loaded";

      const video = document.getElementById("webcam");
      const canvas = document.getElementById("canvas");
      const ctx = canvas.getContext("2d");

      // Access webcam
      navigator.mediaDevices.getUserMedia({ video: { width: 224, height: 224 } })
        .then((stream) => {
          video.srcObject = stream;
          video.onloadedmetadata = () => {
            video.play();
            runInferenceLoop();
          };
        })
        .catch((err) => {
          alert("Webcam access denied: " + err.message);
        });

      async function runInferenceLoop() {
        while (true) {
          ctx.drawImage(video, 0, 0, 224, 224);
          const imageData = ctx.getImageData(0, 0, 224, 224);
          const inputTensor = preprocess(imageData);
          const feeds = { input: inputTensor };

          try {
            const results = await session.run(feeds);
            const output = results.output.data;
            const top = getTopPrediction(output);
            document.getElementById("prediction").textContent = `üî§ Prediction: ${top.label} (${(top.prob * 100).toFixed(1)}%)`;
          } catch (err) {
            document.getElementById("prediction").textContent = "‚ùå Inference error";
            console.error(err);
          }

          await new Promise((resolve) => setTimeout(resolve, 500)); // 2 FPS
        }
      }
    }

    function preprocess(imageData) {
      const { data } = imageData;
      const input = new Float32Array(1 * 3 * 224 * 224);
      for (let i = 0; i < 224 * 224; i++) {
        input[i] = (data[i * 4] / 255 - 0.5) / 0.5;            // R
        input[i + 224 * 224] = (data[i * 4 + 1] / 255 - 0.5) / 0.5;  // G
        input[i + 2 * 224 * 224] = (data[i * 4 + 2] / 255 - 0.5) / 0.5;  // B
      }
      return new ort.Tensor("float32", input, [1, 3, 224, 224]);
    }

    function getTopPrediction(probs) {
      let max = -Infinity;
      let index = -1;
      for (let i = 0; i < probs.length; i++) {
        if (probs[i] > max) {
          max = probs[i];
          index = i;
        }
      }
      return { label: labels[index], prob: max };
    }

    init();
  </script>
</body>
</html>
